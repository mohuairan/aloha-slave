# Pi0.5 åœ¨çº¿è®­ç»ƒåŠå®ç‰©ç­–ç•¥éƒ¨ç½²æŒ‡å—

> æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†å¦‚ä½•åŸºäº Google Colab ä½¿ç”¨å•å¼  A100 (40GB) GPU è¿›è¡Œ Pi0.5 æ¨¡å‹çš„è®­ç»ƒä¸å®ç‰©ç­–ç•¥éƒ¨ç½²æµç¨‹ã€‚

---

## ç›®å½•

- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [Colab ä¿æ´»ä¸å¤‡ä»½](#colab-ä¿æ´»ä¸å¤‡ä»½)
- [æ¨¡å‹ä¸‹è½½ä¸éƒ¨ç½²](#æ¨¡å‹ä¸‹è½½ä¸éƒ¨ç½²)
- [è¿œç¨‹æ¨ç† (Host ç«¯)](#è¿œç¨‹æ¨ç†-host-ç«¯)
- [å®ç‰©æ§åˆ¶ (Client ç«¯)](#å®ç‰©æ§åˆ¶-client-ç«¯)
- [é™„å½•ï¼šå¤¹çˆªæ ‡å®š](#é™„å½•å¤¹çˆªæ ‡å®š)

---
pi0.5åœ¨çº¿è®­ç»ƒåŠå®ç‰©ç­–ç•¥éƒ¨ç½²æŒ‡å—

åŸºäºè°·æ­Œcolabï¼ˆ10ç¾å…ƒä¼šå‘˜ç‰ˆï¼‰å•å¼ A100ï¼ˆ40Gï¼‰è®­ç»ƒ

##å…ˆæ³¨å†Œå¥½ä½ çš„huggingfaceå¸å·ï¼Œåˆ›å»ºå¥½ä»“åº“
ä¿å­˜å¥½huggingfaceå¯†é’¥ï¼è¿™ä¸ªå¾ˆé‡è¦
å¦‚æœæ˜¯æœ¬åœ°ä¿å­˜çš„æ–‡ä»¶ï¼Œä½¿ç”¨å†™å¥½çš„push_to_huggingface.pyæ¥ä¸Šä¼ æ•°æ®é›†åˆ°ä»“åº“
ï¼ï¼æ³¨æ„ä»“åº“ç»“æ„ï¼šè¿›ä»“åº“ä¹‹åç›´æ¥å°±æ˜¯dataæ–‡ä»¶å¤¹ä¸metaæ–‡ä»¶å¤¹ï¼Œä¸å¯ä»¥æ˜¯å…¶ä»–ç»“æ„


git clone --recurse-submodules https://github.com/Physical-Intelligence/openpi.git
cd openpi

## å¦‚æœå·²ç»å…‹éš†äº†ä»“åº“ï¼Œæ›´æ–°å­æ¨¡å—ï¼š
git submodule update --init --recursive

###### å®‰è£…uvåŒ…ç®¡ç†å™¨

OpenPIä½¿ç”¨[uv](https://docs.astral.sh/uv/)ç®¡ç†Pythonä¾èµ–é¡¹ï¼š


```bash
## å®‰è£…uv
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.cargo/env

## éªŒè¯å®‰è£…
uv --version
```

###### å®‰è£…OpenPIä¾èµ–


```bash
## è®¾ç½®ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
GIT_LFS_SKIP_SMUDGE=1 uv sync
GIT_LFS_SKIP_SMUDGE=1 uv pip install -e .
```

**æ³¨æ„**ï¼š`GIT_LFS_SKIP_SMUDGE=1`æ˜¯æ‹‰å–LeRobotä¾èµ–æ‰€å¿…éœ€çš„ã€‚

æ­¤æ—¶è¿è¡Œå½’ä¸€åŒ–å‘ç°huggingfaceçš„datasetæœªç”Ÿæˆtag
LeRobot è¦æ±‚ dataset repo å¿…é¡»æœ‰ä¸€ä¸ªâ€œç‰ˆæœ¬ tagâ€ï¼Œå¦åˆ™ä¼šæŠ¥ï¼š
RevisionNotFoundError: Your dataset must be tagged with a codebase version.

##ä¸ºdatasetåŠ ä¸Štag
åœ¨colabä¸Šè¿è¡Œ
huggingface-cli login

##æ£€æŸ¥
huggingface-cli whoami
##å†è¿è¡Œ
hf repo tag create mo0821/aloha_training_pick_tissue_2 v1 --repo-type dataset
##æˆåŠŸæ·»åŠ tagåˆ°dataset

è¿›å…¥/content/openpi/src/openpi/training/
åœ¨configæ–‡ä»¶TrainConfigä¸­æ·»åŠ ä»¥ä¸‹å­—æ®µ

###### LoRAå¾®è°ƒé…ç½®
**æ˜¾å­˜è¦æ±‚**ï¼š22.5GB+

    TrainConfig(
        name="pi05_aloha_pick_tissue_finetune",
        model=pi0_config.Pi0Config(
            paligemma_variant="gemma_2b_lora", 
            action_expert_variant="gemma_300m_lora",
            pi05=True
        ),
        data=LeRobotAlohaDataConfig(
            repo_id="mo0821/aloha_test",
            assets=AssetsConfig(
                assets_dir="/root/.cache/pi05_base/assets",
                asset_id="trossen",
            ),
            default_prompt="pick up the tissue and put it into box",
            repack_transforms=_transforms.Group(
                inputs=[
                    _transforms.RepackTransform(
                        {
                            "images": {
                                "cam_high": "observation.images.camera_high",
                                "cam_left_wrist": "observation.images.camera_wrist_left",
                                "cam_right_wrist": "observation.images.camera_wrist_right",
                            },
                            "state": "observation.state",
                            "actions": "action",
                        }
                    )
                ]
            ),
        ),
        weight_loader=weight_loaders.CheckpointWeightLoader("/root/.cache/pi05_base/params"),
        num_train_steps=20_000,
        freeze_filter=pi0_config.Pi0Config(
            paligemma_variant="gemma_2b_lora", 
            action_expert_variant="gemma_300m_lora",
            pi05=True
        ).get_freeze_filter(),
        ema_decay=None,  ## LoRAå¾®è°ƒæ—¶å…³é—­EMA
    ),

##è¿è¡Œå½’ä¸€åŒ–ç¨‹åº
uv run scripts/compute_norm_stats.py --config-name pi05_aloha_pick_tissue_finetune

##æŠ¥é”™æ•°æ®é›†ä¸åŠ è½½
æ‰‹åŠ¨ä¸‹è½½æ•°æ®åˆ°
mkdir -p /root/.cache/huggingface/lerobot/mo0821/aloha_test

huggingface-cli download mo0821/aloha_test --repo-type dataset --local-dir /root/.cache/huggingface/lerobot/mo0821/aloha_test
ï¼ˆæˆ–è€…hf downloadï¼‰

##è¿è¡Œè®­ç»ƒç¨‹åº
XLA_PYTHON_CLIENT_MEM_FRACTION=0.99 uv run scripts/train.py pi05_aloha_pick_tissue_finetune --exp-name=my_experiment --overwrite


##ç›®å‰å‡ºç°çš„é—®é¢˜
1ã€è¿è¡Œä¸‹é¢å‘½ä»¤æ—¶
aws s3 sync s3://openpi-assets/checkpoints/pi05_base ./pi05_base/ --no-sign-request
å‘ç°pi05baseæ˜¯ä¸ªç©ºæ–‡ä»¶å¤¹

è§£å†³æ–¹æ³•ï¼š
å®‰è£… Google Cloud SDKï¼š
curl https://sdk.cloud.google.com | bash

##å®‰è£…crcmodåŒ…ï¼Œä¸ç„¶ä¼šä¸‹ä¸ä¸‹æ¥
sudo apt-get install python3-dev gcc -y

pip install -U crcmod

ç›´æ¥ä¸‹è½½
cd ~/.cache

gsutil -m cp -r gs://openpi-assets/checkpoints/pi05_base ./

2ã€ç°åœ¨çš„æ•°æ®æ ¼å¼æ˜¯1.0,è®­ç»ƒéœ€è¦2.0æ ¼å¼ï¼Œè½¬æ¢æ—¶ç”µè„‘å‡ºç°è¿›ç¨‹ç»ˆæ­¢ã€‚

3ã€æŠ¥é”™
/content/openpi## uv run scripts/compute_norm_stats.py --config-name pi0.5_aloha_pick_tissue_finetune
warning: The `tool.uv.dev-dependencies` field (used in `packages/openpi-client/pyproject.toml`) is deprecated and will be removed in a future release; use `dependency-groups.dev` instead
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.07M/4.07M [00:05<00:00, 852kiB/s]
Traceback (most recent call last):
  File "/content/openpi/.venv/lib/python3.11/site-packages/lerobot/common/datasets/lerobot_dataset.py", line 95, in __init__
    self.load_metadata()
  File "/content/openpi/.venv/lib/python3.11/site-packages/lerobot/common/datasets/lerobot_dataset.py", line 105, in load_metadata
    self.info = load_info(self.root)
                ^^^^^^^^^^^^^^^^^^^^
  File "/content/openpi/.venv/lib/python3.11/site-packages/lerobot/common/datasets/utils.py", line 178, in load_info
    info = load_json(local_dir / INFO_PATH)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/openpi/.venv/lib/python3.11/site-packages/lerobot/common/datasets/utils.py", line 146, in load_json
    with open(fpath) as f:
         ^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/root/.cache/huggingface/lerobot/mo0821/aloha_training_pick_tissue_2/meta/info.json'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/openpi/scripts/compute_norm_stats.py", line 117, in <module>
    tyro.cli(main)
  File "/content/openpi/.venv/lib/python3.11/site-packages/tyro/_cli.py", line 229, in cli
    return run_with_args_from_cli()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/openpi/scripts/compute_norm_stats.py", line 98, in main
    data_loader, num_batches = create_torch_dataloader(
                               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/openpi/scripts/compute_norm_stats.py", line 34, in create_torch_dataloader
    dataset = _data_loader.create_torch_dataset(data_config, action_horizon, model_config)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/openpi/src/openpi/training/data_loader.py", line 140, in create_torch_dataset
    dataset_meta = lerobot_dataset.LeRobotDatasetMetadata(repo_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/openpi/.venv/lib/python3.11/site-packages/lerobot/common/datasets/lerobot_dataset.py", line 98, in __init__
    self.revision = get_safe_version(self.repo_id, self.revision)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/openpi/.venv/lib/python3.11/site-packages/lerobot/common/datasets/utils.py", line 330, in get_safe_version
    raise RevisionNotFoundError(
huggingface_hub.errors.RevisionNotFoundError: Your dataset must be tagged with a codebase version.
            Assuming _version_ is the codebase_version value in the info.json, you can run this:
            ```python
            from huggingface_hub import HfApi

            hub_api = HfApi()
            hub_api.create_tag("mo0821/aloha_training_pick_tissue_2", tag="_version_", repo_type="dataset")
            ```
è§£å†³ä¸€éƒ¨åˆ†ï¼Œhuggingfaceçš„datasetæœªç”Ÿæˆtag

##huggingface_hub.errors.RevisionNotFoundError: Your dataset must be tagged with a codebase version.
åœ¨colabä¸Šè¿è¡Œ
huggingface-cli login
æ£€æŸ¥
huggingface-cli whoami
å†è¿è¡Œ
hf repo tag create mo0821/aloha_training_pick_tissue_2 v1 --repo-type dataset
æˆåŠŸæ·»åŠ tagåˆ°dataset



æŠ¥é”™æ•°æ®é›†ä¸åŠ è½½
æ‰‹åŠ¨ä¸‹è½½æ•°æ®åˆ°
mkdir -p /root/.cache/huggingface/lerobot/mo0821/aloha_test

huggingface-cli download mo0821/aloha_test --repo-type dataset --local-dir /root/.cache/huggingface/lerobot/mo0821/aloha_test
ï¼ˆæˆ–è€…hf downloadï¼‰



æ–‡ä»¶è¢«å†™å…¥ï¼šWriting stats to: /content/openpi/assets/pi05_aloha_pick_tissue_finetune/mo0821/aloha_test

å¼€å§‹è®­ç»ƒ
XLA_PYTHON_CLIENT_MEM_FRACTION=0.99 uv run scripts/train.py pi05_aloha_pick_tissue_finetune --exp-name=my_experiment --overwrite


è®°å¾—ç»å¸¸åœ¨äº‘ç›˜é‡Œé¢ä¿å­˜æ•°æ®
!cp -r /content/openpi/checkpoints/pi05_aloha_pick_tissue_finetune /content/drive/MyDrive/


##colabä¿æ´»+äº‘ç›˜è‡ªåŠ¨å¤‡ä»½
PSï¼šéœ€è¦æ¯”è¾ƒå¤§çš„äº‘ç›˜ç©ºé—´
## =============================
## ğŸŒŸ Colab ä¿æ´» + è‡ªåŠ¨å¤‡ä»½è„šæœ¬
import time
from datetime import datetime
import shutil
import os
import sys

## === è®¾ç½®è·¯å¾„ ===
source_folder = "/content/openpi/checkpoints/pi05_aloha_pick_tissue_finetune"
backup_folder = "/content/drive/MyDrive/openpi_checkpoints_backup"

os.makedirs(backup_folder, exist_ok=True)

## === æŒç»­ä¿æŒæ´»è·ƒ + å¤‡ä»½ ===
while True:
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[Heartbeat] Colab active at {now}", flush=True)
    
    ## æ¯éš”30åˆ†é’Ÿå¤‡ä»½ä¸€æ¬¡
    if int(time.time()) % (30 * 60) < 10:  ## é¿å…é‡å¤è§¦å‘
        backup_path = os.path.join(backup_folder, f"backup_{now.replace(':','-')}")
        shutil.copytree(source_folder, backup_path, dirs_exist_ok=True)
        print(f"[Backup] Saved checkpoint to {backup_path}", flush=True)
    
    time.sleep(600)  ## æ¯10åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡
    
##è‡ªåŠ¨å¤‡ä»½çº¿ç¨‹2

import threading
import time
import random

def keep_alive_python():
    """ä½¿ç”¨ Python å®šæ—¶è¾“å‡ºä¿æŒæ´»è·ƒ"""
    messages = [
        "ğŸ”„ Colab ä¿æŒæ´»è·ƒä¸­...",
        "ğŸ“Š æ­£åœ¨å¤„ç†æ•°æ®...",
        "ğŸ¤– AI è®­ç»ƒè¿›è¡Œä¸­...",
        "âš¡ è®¡ç®—ä¸­ï¼Œè¯·å‹¿æ–­å¼€...",
        "ğŸ”¬ å®éªŒè¿è¡Œä¸­..."
    ]
    
    while True:
        ## éšæœºé€‰æ‹©ä¸€æ¡æ¶ˆæ¯è¾“å‡º
        message = random.choice(messages)
        print(f"{time.strftime('%Y-%m-%d %H:%M:%S')} - {message}")
        
        ## æ¯ 55 ç§’è¾“å‡ºä¸€æ¬¡ï¼ˆå°äº60ç§’é¿å…è¶…æ—¶ï¼‰
        time.sleep(55)

def start_keep_alive():
    """å¯åŠ¨åå°ä¿æŒæ´»è·ƒçº¿ç¨‹"""
    thread = threading.Thread(target=keep_alive_python, daemon=True)
    thread.start()
    print("Python ä¿æŒæ´»è·ƒçº¿ç¨‹å·²å¯åŠ¨")
    return thread

## å¯åŠ¨ Python ä¿æŒæ´»è·ƒ
keep_alive_thread = start_keep_alive()


##ä¸‹è½½æ–‡ä»¶
åªéœ€è¦ä¸‹è½½æœ€åä¸€æ¬¡çš„checkpoint
å»ºè®®æ˜¯å…ˆåœ¨colabä¸­è¿è¡Œä¸‹é¢æŒ‡ä»¤å‹ç¼©æ–‡ä»¶
!zip -r /content/checkpoint/pi05_aloha_pick_tissue_finetune_19999.zip \
      /content/drive/MyDrive/openpi/checkpoints/pi05_aloha_pick_tissue_finetune/my_experiment/19999
å†åŒæ­¥åˆ°è°·æ­Œäº‘ç›˜å†è¿›è¡Œä¸‹è½½ï¼Œä¸ç„¶ç›´æ¥ä¸‹è½½æ–‡ä»¶å¤¹ä¼šä¸‹æˆä¸‰å››ä¸ªå‹ç¼©åŒ…ï¼Œæ–‡ä»¶å®Œæ•´æ€§æ— æ³•ä¿è¯

##è°·æ­Œäº‘ç›˜å®Œæ•´æ–‡ä»¶ä¸‹è½½
åœ¨æœ¬åœ°ç”µè„‘ä¸Š
pip install gdown
åœ¨è°·æ­Œäº‘ç›˜ä¸Šå¤åˆ¶å¯¹åº”æ–‡ä»¶å¤¹ï¼ˆåœ¨å…±äº«é€‰é¡¹ä¸­æŠŠæ‰€æœ‰äººå¯è§æ‰“å¼€ï¼‰
https://drive.google.com/drive/folders/1812aDQgMYlkjo7cyLWaT0Lxao4c0dYp8?usp=drive_link
å¦‚ä¸‹ç•Œé¢ä¸‹ï¼Œåœ¨ç½‘å€çš„drive/foldersåé¢çš„ä¸¤ä¸ªä¸‹åˆ’çº¿ä¹‹é—´çš„å°±æ˜¯idï¼Œæ¯”å¦‚è¿™é‡Œåˆ†äº«çš„é“¾æ¥æ˜¯https://drive.google.com/drive/folders/1812aDQgMYlkjo7cyLWaT0Lxao4c0dYp8?usp=drive_linkï¼Œé‚£ä¹ˆidå°±æ˜¯1812aDQgMYlkjo7cyLWaT0Lxao4c0dYp8


gdown https://drive.google.com/uc?id=1812aDQgMYlkjo7cyLWaT0Lxao4c0dYp8 -O  /home/slwang/aloha_data/checkpoint/

-O OUTPUT, --output OUTPUT
                        output file name/path; end with "/"to create a new
                        directory (default: None)
                        
                        
##å…³äºå®æœºç­–ç•¥éƒ¨ç½²é—®é¢˜
openpiè¿™è¾¹é‡‡ç”¨äº†è¿œç¨‹é€šè®¯ï¼Œå¯ä»¥å°†ç­–ç•¥çš„è¿œç¨‹æ¨ç†ï¼ˆé«˜æ€§èƒ½ç”µè„‘ï¼Œæ˜¾å­˜å¤§äºç­‰äº12Gï¼‰ï¼ˆhostç«¯ï¼‰ä¸å®ç‰©æœºæ¢°è‡‚æ§åˆ¶ï¼ˆclientç«¯ï¼‰åˆ†å¼€

##è¿œç¨‹æ¨ç†ï¼ˆhostç«¯ï¼‰ç¯å¢ƒæ­å»ºåŠè¿è¡Œ
å…‹éš†openpiä»“åº“
git clone 
cd openpi
python -m venv .venvï¼ˆè¿™é‡Œåº”è¯¥è¦åˆ›å»ºpython3.11çš„è™šæ‹Ÿç¯å¢ƒï¼‰
source .venv/bin/bash/activate

uv pip install -e .
è¿›å…¥openpi/src/openpi/training/config.py
ä¿®æ”¹TrainConfig
ä¸»è¦æ˜¯assetså­—æ®µ
assets=AssetsConfig(
                assets_dir="/root/.cache/pi05_base/assets",
                asset_id="trossen",
            ),
æŠŠassets_diræ”¹ä¸ºä¸»æ–‡ä»¶å¤¹ä¸‹çš„.catchæ–‡ä»¶å¤¹è€Œä¸æ˜¯rootä¸‹çš„ï¼Œç„¶åæŠŠcheckpointsä¸‹çš„assetsæ–‡ä»¶å¤¹å¤åˆ¶è¿‡å»ï¼Œä¿å­˜
è¿è¡Œ
cd openpi
python scripts/serve_policy.py --env ALOHA \ ##é€‰æ‹©ALOHA
  policy:checkpoint \
  --policy.config "pi05_aloha_pick_tissue_finetune" \ ##TrainConfigé‡Œé¢çš„ä»»åŠ¡å
  --policy.dir /home/jodell/serve_train/openpi/checkpoints/pi05_aloha_pick_tissue_finetune/my_experiment/19999  ##è‡ªå·±çš„æ–‡ä»¶å¤¹
  
è¾“å‡ºå¦‚ä¸‹ï¼š
INFO:absl:Restoring checkpoint from /home/jodell/serve_train/openpi/checkpoints/pi05_aloha_pick_tissue_finetune/my_experiment/19999/params.
INFO:absl:[thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID.
INFO:absl:[process=0] /jax/checkpoint/read/bytes_per_sec: 1.5 GiB/s (total bytes: 6.3 GiB) (time elapsed: 4 seconds) (per-host)
INFO:absl:Finished restoring checkpoint in 4.26 seconds from /home/jodell/serve_train/openpi/checkpoints/pi05_aloha_pick_tissue_finetune/my_experiment/19999/params.
INFO:root:Loaded norm stats from /home/jodell/.cache/pi05_base/assets/trossen
INFO:root:Loaded norm stats from /home/jodell/serve_train/openpi/checkpoints/pi05_aloha_pick_tissue_finetune/my_experiment/19999/assets/trossen
INFO:root:Creating server (host: jodell, ip: 127.0.1.1)
INFO:websockets.server:server listening on 0.0.0.0:8000

éªŒè¯æ¨ç†ç«¯æ­å»ºæˆåŠŸï¼

##å®ç‰©æ§åˆ¶ï¼ˆClientç«¯ï¼‰ç¯å¢ƒæ­å»º
openpiæ–‡æ¡£ä¸­å»ºè®®é‡‡ç”¨dockerè¿›è¡Œç¯å¢ƒæ­å»ºï¼Œè¯¦è§examples/aloha_realæ–‡ä»¶å¤¹ä¸‹readmeæ–‡ä»¶

openpiå®˜æ–¹ç»™å‡ºçš„çš„dockerå¯åŠ¨æ–¹å¼æ˜¯dockerâ€”composeï¼Œåœ¨openpiæ–‡ä»¶å¤¹ä¸‹è¿è¡Œ
docker compose -f examples/aloha_real/compose.yml up 
ä»¥å¯åŠ¨å®ç‰©

è¿™é‡Œæœ‰ä¸€äº›æ³¨æ„äº‹é¡¹ï¼š
æˆ‘ä»¬é€‰æ‹©å°†æ¨ç†ä¸å®æœºæ“æ§åˆ†å¼€ï¼Œå› æ­¤åœ¨å®æœºä¸Šä¸éœ€è¦è¿è¡Œopenpiâ€”serveré•œåƒï¼Œæ‰€ä»¥åœ¨docker-composeæ–‡ä»¶ä¸­åˆ å»openpi-serverç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬runtimeé…ç½®ä¸­çš„dependsâ€”onï¼šopenpi-server

ç¼–è¯‘æ—¶é‡åˆ°æŠ¥é”™

********************************************** Starting installation! This process may take around 15 Minutes! ********************************************** 
Err:1 http://mirrors.ustc.edu.cn/ubuntu focal InRelease Temporary failure resolving 'mirrors.ustc.edu.cn'
Err:2 http://snapshots.ros.org/noetic/final/ubuntu focal InRelease Temporary failure resolving 'snapshots.ros.org'

ç»æŸ¥ï¼Œé—®é¢˜å‡ºåœ¨
RUN curl 'https://raw.githubusercontent.com/Interbotix/interbotix_ros_manipulators/main/interbotix_ros_xsarms/install/amd64/xsarm_amd64_install.sh' > xsarm_amd64_install.sh
è¿™é‡Œæ‹‰å–çš„shæ–‡ä»¶ä¸­åŒ…å«æœ‰sudoæŒ‡ä»¤ï¼ŒsudoæŒ‡ä»¤åœ¨dockerfileè¿è¡Œæ—¶ä¼šå¯¼è‡´é”™è¯¯ï¼Œå› æ­¤éœ€è¦åœ¨buildæ—¶åˆ é™¤shæ–‡ä»¶ä¸­çš„æ‰€æœ‰æŒ‡ä»¤å‰é¢çš„sudo
å› æ­¤åœ¨åé¢æ·»åŠ 
RUN sed -i 's/sudo //g' xsarm_amd64_install.sh


##æœºæ¢°è‡‚ä¸realsenseçš„é…ç½®ä¿®æ”¹
dockerfileæŠŠæœºå™¨äººçš„é…ç½®æ–‡ä»¶æŒ‚è½½åˆ°äº†å®¿ä¸»æœºçš„openpiå·¥ä½œæ–‡ä»¶å¤¹ä¸‹çš„/openpi_new/openpi/third_party/aloha/aloha_scripts/robot_utils.pyæ–‡ä»¶ä¸­

åœ¨dockerfileä¸­æ·»åŠ ä»¥ä¸‹å†…å®¹
## å›ºå®š Interbotix X-Series å››ä¸ªæœºæ¢°è‡‚çš„ USB è®¾å¤‡åç§°
RUN echo "## Interbotix Arm UDEV Rules" >> /etc/udev/rules.d/99-interbotix-arms.rules && \
    echo 'SUBSYSTEM=="tty", ATTRS{serial}=="FTAAMN4B", ENV{ID_MM_DEVICE_IGNORE}="1", SYMLINK+="ttyDXL_master_right"' >> /etc/udev/rules.d/99-interbotix-arms.rules && \
    echo 'SUBSYSTEM=="tty", ATTRS{serial}=="FTAAMMSJ", ENV{ID_MM_DEVICE_IGNORE}="1", SYMLINK+="ttyDXL_master_left"' >> /etc/udev/rules.d/99-interbotix-arms.rules && \
    echo 'SUBSYSTEM=="tty", ATTRS{serial}=="FTAAMN3J", ENV{ID_MM_DEVICE_IGNORE}="1", SYMLINK+="ttyDXL_puppet_left"' >> /etc/udev/rules.d/99-interbotix-arms.rules && \
    echo 'SUBSYSTEM=="tty", ATTRS{serial}=="FTA9DPY2", ENV{ID_MM_DEVICE_IGNORE}="1", SYMLINK+="ttyDXL_puppet_right"' >> /etc/udev/rules.d/99-interbotix-arms.rules

## ä½¿ç”¨ sed å‘½ä»¤ä¿®æ”¹æŒ‡å®šå†…å®¹ - the gripper
RUN sed -i 's/LEADER_GRIPPER_CLOSE_THRESH = 0.0/LEADER_GRIPPER_CLOSE_THRESH = -1.4/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/LEADER_GRIPPER_POSITION_OPEN = 0.0323/LEADER_GRIPPER_POSITION_OPEN = 0.02417/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/LEADER_GRIPPER_POSITION_CLOSE = 0.0185/LEADER_GRIPPER_POSITION_CLOSE = 0.01244/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/FOLLOWER_GRIPPER_POSITION_OPEN = 0.0579/FOLLOWER_GRIPPER_POSITION_OPEN = 0.05800/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/FOLLOWER_GRIPPER_POSITION_CLOSE = 0.0440/FOLLOWER_GRIPPER_POSITION_CLOSE = 0.01844/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/LEADER_GRIPPER_JOINT_OPEN = 0.8298/LEADER_GRIPPER_JOINT_OPEN = -0.8/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/LEADER_GRIPPER_JOINT_CLOSE = -0.0552/LEADER_GRIPPER_JOINT_CLOSE = -1.65/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/FOLLOWER_GRIPPER_JOINT_OPEN = 1.6214/FOLLOWER_GRIPPER_JOINT_OPEN = 1.4910/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py && \
    sed -i 's/FOLLOWER_GRIPPER_JOINT_CLOSE = 0.6197/FOLLOWER_GRIPPER_JOINT_CLOSE = 0.0/' /root/interbotix_ws/src/aloha/aloha_scripts/robot_utils.py

ä¿®æ”¹source /opt/ros/noetic/setup.sh && source /root/interbotix_ws/devel/setup.sh && "$@"
ä¸º
set -e
/lib/systemd/systemd-udevd --daemon
udevadm control --reload && udevadm trigger
source /opt/ros/noetic/setup.sh && source /root/interbotix_ws/devel/setup.sh
exec "$@"

dockerfileæŠŠç›¸æœºçš„é…ç½®æ–‡ä»¶æŒ‚è½½åˆ°äº†å®¿ä¸»æœºçš„openpiå·¥ä½œæ–‡ä»¶å¤¹ä¸‹çš„/openpi_new/openpi/third_party/aloha/aloha_scripts/realsense_publisher.pyæ–‡ä»¶ï¼Œåœ¨æ­¤å¤„ä¿®æ”¹realsenseD405çš„åºåˆ—å·
camera_names = ['cam_left_wrist', 'cam_high', 'cam_low', 'cam_right_wrist']
camera_sns = ['427622271497', '427622272971', '427622271439', '427622270353']


ä¿®æ”¹å®Œæˆä¹‹åï¼Œè¿è¡Œ
docker compose -f examples/aloha_real/compose.yml up --build 
è¿›è¡Œç¼–è¯‘

##æ¨ç†




##æ ‡å®šå¤¹çˆªä½ç½®
roslaunch interbotix_xsarm_control xsarm_control.launch \
  robot_model:=vx300s \
  robot_name:=puppet_right \
  port:=/dev/ttyDXL_puppet_right \
  use_rviz:=false \
  use_joint_pub_gui:=false

rosservice call /puppet_right/get_joint_states



rosrun topic_tools throttle messages /puppet_right/joint_states 1.0 /puppet_right/joint_states_slow

rostopic echo /puppet_right/joint_states_slow | grep position




